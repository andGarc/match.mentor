{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode input text and get BERT embeddings\n",
    "def get_bert_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', max_length=512, truncation=True)\n",
    "    outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)  # Mean pooling over tokens\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity between two vectors\n",
    "def cosine_similarity_vec(vec1, vec2):\n",
    "    return cosine_similarity(vec1.detach().numpy(), vec2.detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "input_text = \"I like to eat mac and cheese\"\n",
    "input_embedding = get_bert_embedding(input_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [\"I don't like to eat mac and cheese\", \"What is it?\",\n",
    "           \"I like to eat cheese\", \"I like to eat mac and cheese\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity with other items\n",
    "similarities = {}\n",
    "for other_item in dataset:\n",
    "    other_embedding = get_bert_embedding(other_item)\n",
    "    similarity_score = cosine_similarity_vec(input_embedding, other_embedding)\n",
    "    similarities[other_item] = similarity_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommendations: [('I like to eat mac and cheese', array([[1.]], dtype=float32)), (\"I don't like to eat mac and cheese\", array([[0.9144159]], dtype=float32)), ('I like to eat cheese', array([[0.8895547]], dtype=float32)), ('What is it?', array([[0.46155483]], dtype=float32))]\n"
     ]
    }
   ],
   "source": [
    "# Get top N recommendations based on cosine similarity\n",
    "top_recommendations = sorted(similarities.items(), key=lambda x: x[1], reverse=True)[:4]\n",
    "print(\"Top recommendations:\", top_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define weights for criteria\n",
    "weights = {\n",
    "    'gender': 0.6,\n",
    "    'actor': 0.4,\n",
    "    # Add more criteria and adjust weights accordingly\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example criteria values for the input\n",
    "input_criteria = {\n",
    "    'gender': 'Male',\n",
    "    'actor': 'Tom Hanks',\n",
    "    # Add more criteria values as needed\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [{'gender': 'Female', 'actor': 'Tom Hanks', 'description':'I like mac and cheese'},\n",
    "           {'gender': 'Male', 'actor': 'Tom Hanks', 'description':'I like cheese'},\n",
    "           {'gender': 'Male', 'actor': 'Tom Hanks', 'description':'What is is?'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_similarities = {}\n",
    "for item in dataset:\n",
    "    text = item['description']  # Extract text from the dictionary\n",
    "    other_embedding = get_bert_embedding(text)\n",
    "    similarity_score = cosine_similarity_vec(input_embedding, other_embedding)\n",
    "\n",
    "    # Apply adjustments based on criteria\n",
    "    adjusted_score = similarity_score\n",
    "    for criterion, weight in weights.items():\n",
    "        if criterion in input_criteria and input_criteria[criterion] == item.get(criterion):\n",
    "            adjusted_score += weight * 0.1  # Adjust by a factor based on criterion importance\n",
    "\n",
    "    adjusted_similarities[text] = adjusted_score  # Store similarity scores by text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommendations: [('I like mac and cheese', array([[0.97068244]], dtype=float32)), ('I like cheese', array([[0.8526221]], dtype=float32)), ('What is is?', array([[0.5788031]], dtype=float32))]\n"
     ]
    }
   ],
   "source": [
    "# Get top N recommendations based on adjusted similarity scores\n",
    "top_recommendations = sorted(adjusted_similarities.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "print(\"Top recommendations:\", top_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
